{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOLsO5_FhfDv"
   },
   "source": [
    "## Image Retrieval 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4654,
     "status": "ok",
     "timestamp": 1595824037355,
     "user": {
      "displayName": "‍이정수[ 학부졸업 / 산업경영공학부 ]",
      "photoUrl": "",
      "userId": "12549429419312222565"
     },
     "user_tz": -540
    },
    "id": "6HuVSgv1hfDw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2YwM6V9hfDy"
   },
   "source": [
    "\n",
    "## Feature Extractor (Color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r84uG-czhfDz"
   },
   "outputs": [],
   "source": [
    "#  extract 3D HSV color histogram from images\n",
    "class Color_Extractor:\n",
    "    def __init__(self, bins):\n",
    "        # store # of bins for histogram\n",
    "        self.bins = bins\n",
    "\n",
    "    # convert RGB to HSV and \n",
    "    # initialize features to quantify and represent the image\n",
    "    def describe(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        features = []\n",
    "\n",
    "        # grab dimensions and computer center of image\n",
    "        # from beginning 0 to end-1 = 1, i.e. shape[0] & shape[1]\n",
    "        (h, w) = image.shape[:2]\n",
    "        (cx, cy) = (int(w * 0.5), int(h * 0.5))\n",
    "\n",
    "        # divide image into top-left, top-right, bottom-right, bottom-left corner segments as mask\n",
    "        segments = [(0,cx,0,cy), (0,cx,cy,h), (cx,w,cy,h), (cx,w,0,cy)]\n",
    "\n",
    "        # construct an elliptical mask representing the center of the image\n",
    "        (axesX, axesY) = (int(w * 0.75 / 2), int(h * 0.75 / 2))\n",
    "        ellipse_mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "        cv2.ellipse(ellipse_mask, (cx, cy), (axesX, axesY), 0, 0, 360, (255, 255, 255), -1)\n",
    "\n",
    "        # loop over mask corners\n",
    "        for seg in segments:\n",
    "            # construct mask for each corner by np.zeros()\n",
    "            corner_mask = np.zeros(image.shape[:2], dtype = 'uint8')\n",
    "            # draw rectangle mask on corner_mask object\n",
    "            corner_mask[seg[0]:seg[1], seg[2]:seg[3]] = 255\n",
    "            corner_mask = cv2.subtract(corner_mask, ellipse_mask)\n",
    "\n",
    "            # extract hsv histogram\tfrom segment of image with mask\t\n",
    "            hist = self.histogram(image, corner_mask)\n",
    "\n",
    "            # update feature vector\n",
    "            features.extend(hist)\n",
    "\n",
    "        # extract hsv histogram from ellipse with mask\n",
    "        hist_ellipse = self.histogram(image, ellipse_mask)\n",
    "        features.extend(hist_ellipse)\n",
    "\n",
    "        return ???\n",
    "    \n",
    "    # Calculate the histogram of the masked region of the image\n",
    "    def histogram(self,image, mask):\n",
    "        # use number of bins per channel; \n",
    "        hist = cv2.calcHist([image], [0,1,2], mask, self.bins, [0, 256, 0, 256, 0, 256])\n",
    "        \n",
    "        # normalize histogram to obtain scale invariance\n",
    "        hist = cv2.normalize(hist, None).flatten()\n",
    "    \n",
    "        return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvZZ3fVwhfD1"
   },
   "outputs": [],
   "source": [
    "def extract_color_features(path):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    list_imgs_names = os.listdir(path)\n",
    "    color_extractor = Color_Extractor((8, 8, 8))\n",
    "    image_all = []\n",
    "    \n",
    "    # Iterate through the list of images\n",
    "    for img_name in list_imgs_names:        \n",
    "        # Read in each one by one\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = mpimg.imread(img_path) # Read the images\n",
    "        image = ???(image, (224, 224), mode='constant') # Resize the images\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        feature_image = np.copy(image)\n",
    "        \n",
    "        feature = np.array(color_extractor.describe(feature_image))\n",
    "        feature = feature / LA.norm(???) # Feature Normalization\n",
    "        features.append(feature)\n",
    "        image_all.append(img_name)\n",
    "    \n",
    "    time_elapsed = ???\n",
    "    \n",
    "    print('Feature extraction complete in {:.02f}s'.format(time_elapsed % 60))\n",
    "    \n",
    "    # Return list of feature vectors\n",
    "    return np.array(features), image_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQOk0dk7hfD3"
   },
   "outputs": [],
   "source": [
    "def test_color_features():\n",
    "    print('Extract features from data')\n",
    "    path = './data'\n",
    "    feats, image_list = extract_color_features(path)\n",
    "\n",
    "    print('Extract features from query image')\n",
    "    test = './test'\n",
    "    feat_single, image = extract_color_features(test)\n",
    "    \n",
    "    # Calculate the scores\n",
    "    scores  = ???(feat_single, feats.T)  # 스코어 구하기\n",
    "    sort_ind = ???(scores)[0][::-1]      # 스코어 정렬하기\n",
    "    scores = scores[0, sort_ind]\n",
    "\n",
    "    # Show the results\n",
    "    maxres = 10\n",
    "    imlist = [image_list[index] for i, index in enumerate(sort_ind[0:maxres])]\n",
    "    print (\"top %d images in order are: \" %maxres, imlist)\n",
    "\n",
    "    fig=plt.figure(figsize=(16, 10))\n",
    "    for i in range(len(imlist)):\n",
    "        sample = imlist[i]\n",
    "        img = mpimg.imread('./data' + '/' + sample)\n",
    "        ax = fig.add_subplot(2, 5, i+1)\n",
    "        ax.autoscale()\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        ax.set_title('{:.3f}%'.format(scores[i]))\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rshd7EDjhfD5",
    "outputId": "2668eb82-65e8-4b7d-c4d6-2cef72ba6fce",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_color_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywbwguSuhfED"
   },
   "source": [
    "## Feature Extractor (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQJIzgqthfEE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.vgg19 = torchvision.models.vgg19(pretrained = True) # vgg 19 model is imported\n",
    "        #print(vgg19)\n",
    "        self.vgg19.classifier = self.vgg19.classifier[0:4]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.vgg19(x)\n",
    "        return out\n",
    "\n",
    "# Set our model with pre-trained model \n",
    "vgg19 = VGG19().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bTedPL6hfEF"
   },
   "source": [
    "## Feature Extractor (ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tE5ssg-4hfEG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the network to extract the features\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        resnet = torchvision.models.resnet50(pretrained = True) # resnet 50 model is imported\n",
    "        \n",
    "        #print(resnet)\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "\n",
    "    def forward(self, x):\n",
    "        ???\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        ???\n",
    "        out = F.avg_pool2d(out, kernel_size=7, stride=7)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Set our model with pre-trained model \n",
    "resnet = ResNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH9zfPRyhfEI"
   },
   "outputs": [],
   "source": [
    "# Extract ConvNet Features (VGG19, ResNet)\n",
    "def extract_deep_features(path, feature_extractor, feature_size):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    list_imgs_names = os.listdir(path) #list_imgs_names\n",
    "    N = len(list_imgs_names)\n",
    "    feature_all = np.zeros((N, feature_size)) # create an array to store features\n",
    "    image_all = [] # define empy array to store image names\n",
    "    \n",
    "    transform = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # extract features \n",
    "    for index, img_name in enumerate(list_imgs_names):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        \n",
    "        # Image Read & Resize\n",
    "        image_np = Image.open(img_path) # Read the images\n",
    "        image_np = np.array(image_np)\n",
    "        image_np = resize(image_np, (224, 224), mode='constant') # Resize the images\n",
    "        image_np = torch.from_numpy(image_np).permute(2, 0, 1).float()\n",
    "        image_np = transform(image_np)\n",
    "        image_np = Variable(image_np.unsqueeze(0))   #bs, c, h, w\n",
    "        image_np = image_np.cuda()\n",
    "        \n",
    "        # Extract Feature\n",
    "        feature = feature_extractor(image_np)\n",
    "        feature = feature.squeeze().cpu().data.numpy()\n",
    "        feature = feature.reshape((1, feature_size)) # Feature Flatten\n",
    "        feature = feature / LA.norm(feature) # Feature Normalization\n",
    "        feature_all[index] = feature\n",
    "        image_all.append(img_name)\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    print('Feature extraction complete in {:.02f}s'.format(time_elapsed % 60))\n",
    "\n",
    "    return feature_all, image_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zn0D046DhfEJ"
   },
   "outputs": [],
   "source": [
    "def test_deep_feature(feature_extractor, feature_size):\n",
    "    # Extract features from the dataset\n",
    "    print('Extract features from data')\n",
    "    path = './data'\n",
    "    feats, image_list = extract_deep_features(path, feature_extractor, feature_size=feature_size)\n",
    "\n",
    "    # test image path\n",
    "    print('Extract features from query image')\n",
    "    test = './test'\n",
    "    feat_single, image = extract_deep_features(test, feature_extractor, feature_size=feature_size)\n",
    "    \n",
    "    # Calculate the scores\n",
    "    scores  = np.dot(feat_single, feats.T)\n",
    "    sort_ind = np.argsort(scores)[0][::-1] # sort the scores\n",
    "    scores = scores[0, sort_ind]\n",
    "\n",
    "    # Show the results\n",
    "    maxres = 10\n",
    "    imlist = [image_list[index] for i, index in enumerate(sort_ind[0:maxres])]\n",
    "    print (\"top %d images in order are: \" %maxres, imlist)\n",
    "\n",
    "    fig=plt.figure(figsize=(16, 10))\n",
    "    for i in range(len(imlist)):\n",
    "        sample = imlist[i]\n",
    "        img = mpimg.imread('./data' + '/' + sample)\n",
    "        ax = fig.add_subplot(2, 5, i+1)\n",
    "        ax.autoscale()\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        ax.set_title('{:.3f}%'.format(scores[i]))\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cct12xszhfEL",
    "outputId": "c33f0e88-97b1-45fc-bdc2-3ae27fc00380",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VGG19 Image Retrieval Results\n",
    "test_deep_feature(vgg19, feature_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsxNA8rUhfEN",
    "outputId": "71afbd9f-6bc3-4073-94c0-097cb597d6d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ResNet50 Image Retrieval Results\n",
    "test_deep_feature(resnet, feature_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1_Image_Retrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1596544383675"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}